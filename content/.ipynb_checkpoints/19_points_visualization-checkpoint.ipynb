{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **NOTE**: some of this material has been ported and adapted from \"Lab 9\" in [Arribas-Bel (2016)](http://darribas.org/gds15/labs/Lab_09.html).\n",
    "\n",
    "This notebook covers a brief introduction on how to visualize and analyze point patterns. To demonstrate this, we will use a dataset of all the AirBnb listings in the city of Austin.\n",
    "\n",
    "Before anything, let us load up the libraries we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mplleaflet as mpll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first set the paths to the datasets we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this to point to the right file in your computer\n",
    "listings_link = 'data/listings.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core dataset we will use is `listings.csv`, which contains a lot of information about each individual location listed at AirBnb within Austin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = pd.read_csv(listings_link)\n",
    "lst.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that one record displays a very odd location and, for the sake of the illustration, we will remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd = lst.loc[lst.longitude>-80, ['longitude', 'latitude']]\n",
    "odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = lst.drop(odd.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most straighforward way to get a first glimpse of the distribution of the data is to plot their latitude and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"longitude\", y=\"latitude\", data=lst);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this does not neccesarily tell us much about the dataset or the distribution of locations within Austin. There are two main challenges in interpreting the plot: one, there is lack of context, which means the points are not identifiable over space (unless you are so familiar with lon/lat pairs that they have a clear meaning to you); and two, in the center of the plot, there are so many points that it is hard to tell any pattern other than a big blurb of blue.\n",
    "\n",
    "Let us first focus on the first problem, geographical context. The quickest and easiest way to provide context to this set of points is to overlay a general map. If we had an image with the map or a set of several data sources that we could aggregate to create a map, we could build it from scratch. But in the XXI Century, the easiest is to overlay our point dataset on top of a web map. In this case, we will use [Leaflet](http://leafletjs.com/), and we will convert our underlying `matplotlib` points with `mplleaflet`. The full dataset (+5k observations) is a bit too much for leaflet to plot it directly on screen, so we will obtain a random sample of 100 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: `mpll.display` turned off to be able to compile the website,\n",
    "#       comment out the last line of this cell for rendering Leaflet map.\n",
    "rids = np.arange(lst.shape[0])\n",
    "np.random.shuffle(rids)\n",
    "f, ax = plt.subplots(1, figsize=(6, 6))\n",
    "lst.iloc[rids[:100], :].plot(kind='scatter', x='longitude', y='latitude', \\\n",
    "                      s=30, linewidth=0, ax=ax);\n",
    "mpll.display(fig=f,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map allows us to get a much better sense of where the points are and what type of location they might be in. For example, now we can see that the big blue blurb has to do with the urbanized core of Austin.\n",
    "\n",
    "### `bokeh` alternative\n",
    "\n",
    "Leaflet is not the only technology to display data on maps, although it is probably the default option in many cases. When the data is larger than \"acceptable\", we need to resort to more technically sophisticated alternatives. One option is provided by `bokeh` and its `datashaded` submodule (see [here](https://anaconda.org/jbednar/nyc_taxi/notebook) for a very nice introduction to the library, from where this example has been adapted).\n",
    "\n",
    "Before we delve into `bokeh`, let us reproject our original data (lon/lat coordinates) into Web Mercator, as `bokeh` will expect them. To do that, we turn the coordinates into a `GeoSeries`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "xys_wb = gpd.GeoSeries(lst[['longitude', 'latitude']].apply(Point, axis=1), \\\n",
    "                      crs=\"+init=epsg:4326\")\n",
    "xys_wb = xys_wb.to_crs(epsg=3857)\n",
    "x_wb = xys_wb.apply(lambda i: i.x)\n",
    "y_wb = xys_wb.apply(lambda i: i.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to setup the plot in `bokeh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.tile_providers import STAMEN_TERRAIN\n",
    "output_notebook()\n",
    "\n",
    "minx, miny, maxx, maxy = xys_wb.total_bounds\n",
    "y_range = miny, maxy\n",
    "x_range = minx, maxx\n",
    "\n",
    "def base_plot(tools='pan,wheel_zoom,reset,hover',plot_width=600, plot_height=400, **plot_args):\n",
    "    p = figure(tools=tools, plot_width=plot_width, plot_height=plot_height,\n",
    "        x_range=x_range, y_range=y_range, outline_line_color=None,\n",
    "        min_border=0, min_border_left=0, min_border_right=0,\n",
    "        min_border_top=0, min_border_bottom=0, **plot_args)\n",
    "    \n",
    "    p.axis.visible = False\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    return p\n",
    "    \n",
    "options = dict(line_color=None, fill_color='#800080', size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And good to go for mapping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: `show` turned off to be able to compile the website,\n",
    "#       comment out the last line of this cell for rendering.\n",
    "p = base_plot()\n",
    "p.add_tile(STAMEN_TERRAIN)\n",
    "p.circle(x=x_wb, y=y_wb, **options)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can quickly see, `bokeh` is substantially faster at rendering larger amounts of data.\n",
    "\n",
    "The second problem we have spotted with the first scatter is that, when the number of points grows, at some point it becomes impossible to discern anything other than a big blur of color. To some extent, interactivity gets at that problem by allowing the user to zoom in until every point is an entity on its own. However, there exist techniques that allow to summarize the data to be able to capture the overall pattern at once. Traditionally, kernel density estimation (KDE) has been one of the most common solutions by approximating a continuous surface of point intensity. In this context, however, we will explore a more recent alternative suggested by the [`datashader`](https://github.com/bokeh/datashader) library (see the [paper](http://www.crest.iu.edu/publications/prints/2014/Cottam2014OutOfCore.pdf) if interested in more details).\n",
    "\n",
    "Arguably, our dataset is not large enough to justify the use of a reduction technique like datashader, but we will create the plot for the sake of the illustration. Keep in mind, the usefulness of this approach increases the more points you need to be plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: `show` turned off to be able to compile the website,\n",
    "#       comment out the last line of this cell for rendering.\n",
    "\n",
    "import datashader as ds\n",
    "#from datashader.callbacks import InteractiveImage\n",
    "from datashader.bokeh_ext import InteractiveImage\n",
    "from datashader.colors import viridis\n",
    "from datashader import transfer_functions as tf\n",
    "from bokeh.tile_providers import STAMEN_TONER\n",
    "\n",
    "p = base_plot()\n",
    "p.add_tile(STAMEN_TONER)\n",
    "\n",
    "pts = pd.DataFrame({'x': x_wb, 'y': y_wb})\n",
    "pts['count'] = 1\n",
    "def create_image90(x_range, y_range, w, h):\n",
    "    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n",
    "    agg = cvs.points(pts, 'x', 'y',  ds.count('count'))\n",
    "    img = tf.shade(agg.where(agg > np.percentile(agg,90)), \\\n",
    "                         cmap=viridis, how='eq_hist')\n",
    "    return tf.dynspread(img, threshold=0.1, max_px=4)\n",
    "    \n",
    "InteractiveImage(p, create_image90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key advandage of `datashader` is that is decouples the point processing from the plotting. That is the bit that allows it to be scalable to truly large datasets (e.g. millions of points). Essentially, the approach is based on generating a very fine grid, counting points within pixels, and encoding the count into a color scheme. In our map, this is not particularly effective because we do not have too many points (the previous plot is probably a more effective one) and esssentially there is a pixel per location of every point. However, hopefully this example shows how to create this kind of scalable maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation\n",
    "\n",
    "A common alternative when the number of points grows is to replace plotting every single point by estimating the continuous observed probability distribution. In this case, we will not be visualizing the points themselves, but an abstracted surface that models the probability of point density over space. The most commonly used method to do this is the so called kernel density estimate (KDE). The idea behind KDEs is to count the number of points in a continious way. Instead of using discrete counting, where you include a point in the count if it is inside a certain boundary and ignore it otherwise, KDEs use functions (kernels) that include points but give different weights to each one depending of how far of the location where we are counting the point is.\n",
    "\n",
    "Creating a KDE is very straightfoward in Python. In its simplest form, we can run the following single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(lst['longitude'], lst['latitude'], shade=True, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to include additional layers of data to provide context, we can do so in the same way we would layer up different elements in `matplotlib`. Let us load first the Zip codes in Austin, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc = gpd.read_file('data/Zipcodes.geojson')\n",
    "zc.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to overlay both layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "\n",
    "zc.plot(color='white', linewidth=0.1, ax=ax)\n",
    "\n",
    "sns.kdeplot(lst['longitude'], lst['latitude'], \\\n",
    "            shade=True, cmap='Purples', \\\n",
    "            ax=ax);\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## `bokeh` alternative\n",
    "\n",
    "pts.head()\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Setup kernel\n",
    "kde = KernelDensity(metric='euclidean',\n",
    "                    kernel='gaussian', algorithm='ball_tree')\n",
    "# Bandwidth selection\n",
    "gs = GridSearchCV(kde, \\\n",
    "                {'bandwidth': np.linspace(0.1, 1.0, 30)}, \\\n",
    "                cv=3)\n",
    "%time cv = gs.fit(pts[['x', 'y']].values)\n",
    "bw = cv.best_params_['bandwidth']\n",
    "kde.bandwidth = bw\n",
    "# Fit the KDE\n",
    "kde.fit(pts[['x', 'y']].values)\n",
    "\n",
    "# Build a mesh\n",
    "minX, minY = pts[['x', 'y']].values.min(axis=0)\n",
    "maxX, maxY = pts[['x', 'y']].values.max(axis=0)\n",
    "bbox = [minX, minY, maxX, maxY]\n",
    "mn = 100\n",
    "mx = np.linspace(minX, maxX, mn)\n",
    "my = np.linspace(minY, maxY, mn)\n",
    "mxx, myy = np.meshgrid(mx, my)\n",
    "mxxyy = np.hstack((mxx.reshape(-1, 1), myy.reshape(-1, 1)))\n",
    "# Fit to the KDE\n",
    "d = kde.score_samples(mxxyy).reshape(mn, mn)\n",
    "\n",
    "print pts.min()['x'], pts.min()['y']\n",
    "\n",
    "print pts.max()['x'], pts.max()['y']\n",
    "\n",
    "mxxyy.max(axis=0)\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "p = base_plot()\n",
    "p.add_tile(STAMEN_TERRAIN)\n",
    "\n",
    "p.image(image=[d], x=minX, y=minY, dw=maxX-minX, dh=maxY-minY, \\\n",
    "        alpha=0.001, palette=\"Blues9\")\n",
    "\n",
    "show(p)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "> *Split the dataset by type of property and create a map for the five most common types.*\n",
    "\n",
    "Consider the following sorting of property types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst.property_type.groupby(lst.property_type)\\\n",
    "                 .count()\\\n",
    "                 .sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
